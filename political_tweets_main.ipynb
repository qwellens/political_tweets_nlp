{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "6864FinalProject.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "KWb0m_Eh_p5l"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez0bGAAtTO9z",
        "colab_type": "code",
        "outputId": "a2681fd0-720c-41d5-8139-47c761880229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zF68fgflrD4u",
        "colab_type": "text"
      },
      "source": [
        "https://www.analyticsvidhya.com/blog/2020/01/first-text-classification-in-pytorch/\n",
        "\n",
        "https://github.com/Shawn1993/cnn-text-classification-pytorch/blob/master/train.py\n",
        "\n",
        "https://arxiv.org/abs/1408.5882\n",
        "\n",
        "https://www.kaggle.com/leighplt/pytorch-torchtext-glove\n",
        "\n",
        "https://pytorch.org/docs/stable/nn.html#conv2d"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mx0ANdomX_Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, utils\n",
        "import random\n",
        "SEED = 1200\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3j36TMJe1Sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "clintontrump_path = \"/content/drive/My Drive/6.864/finalproject/clinton_trump_clean.csv\"\n",
        "alltweets_path = \"/content/drive/My Drive/6.864/finalproject/ExtractedTweets.csv\"\n",
        "\n",
        "clintontrump = pd.read_csv(clintontrump_path)\n",
        "alltweets = pd.read_csv(alltweets_path)\n",
        "# clintontrump = clintontrump[['id', 'handle', 'text']].rename(columns={'id':'Party', 'handle':'Handle', 'text':'Tweet'})\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec5luumofqYV",
        "colab_type": "code",
        "outputId": "8ddfb6b5-2936-4123-b018-8c6b25739c62",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "print(alltweets[0:1][\"Tweet\"])\n",
        "print(alltweets.columns)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    Today, Senate Dems vote to #SaveTheInternet. P...\n",
            "Name: Tweet, dtype: object\n",
            "Index(['Party', 'Handle', 'Tweet'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rZf41zaLj9di",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchtext import data    \n",
        "TEXT = data.Field(tokenize='spacy',batch_first=True,include_lengths=True)\n",
        "LABEL = data.LabelField(dtype = torch.long, batch_first=True)\n",
        "\n",
        "#CLTR VS ALL\n",
        "fields = [('Party', None), ('Handle',LABEL),('Tweet', TEXT)]\n",
        "# fields = [('Party', LABEL), ('Handle',None),('Tweet', TEXT)]\n",
        "\n",
        "#CLTR VS ALL\n",
        "#loading custom dataset\n",
        "# all_data=data.TabularDataset(path = clintontrump_path,format = 'csv',fields = fields,skip_header = True)\n",
        "all_data=data.TabularDataset(path = alltweets_path,format = 'csv',fields = fields,skip_header = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkldMoUhmu-M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#CLTR VS ALL\n",
        "train_data, valid_data, test_data = all_data.split(split_ratio=[0.7, 0.2, 0.1], stratified=True, strata_field = 'Handle', random_state = random.seed(SEED))\n",
        "# train_data, valid_data, test_data = all_data.split(split_ratio=[0.7, 0.2, 0.1], stratified=True, strata_field = 'Party', random_state = random.seed(SEED))\n",
        "\n",
        "TEXT.build_vocab(train_data, min_freq=3 , vectors = \"glove.6B.100d\")  \n",
        "LABEL.build_vocab(train_data)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrAm4ebbKkoC",
        "colab_type": "code",
        "outputId": "f3e432a2-743d-4a8c-a870-2487fc6a1d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(train_data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60518\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqXxTHHA50Od",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Size of TEXT vocabulary:\",len(TEXT.vocab))\n",
        "print(\"Size of LABEL vocabulary:\",len(LABEL.vocab))\n",
        "print(TEXT.vocab.freqs.most_common(30))  \n",
        "print(TEXT.vocab.stoi)   \n",
        "\n",
        "VOCAB_SIZE = len(TEXT.vocab)\n",
        "NUM_CATEGORIES = len(LABEL.vocab)\n",
        "\n",
        "embs_vocab = TEXT.vocab.vectors\n",
        "\n",
        "print(NUM_CATEGORIES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3Ske5R2BBwS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
        "    (train_data, valid_data, test_data), \n",
        "    batch_sizes = (BATCH_SIZE, BATCH_SIZE, len(test_data)),\n",
        "    sort_key = lambda x: len(x.Tweet),\n",
        "    sort_within_batch=True,\n",
        "    device = device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io77cjBzFLzU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class CNN(nn.Module):\n",
        "  def __init__(self, embs_vocab, embed_size, hidden_size, num_conv_layers, num_categories, dropout=0.):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    input_channels = 1\n",
        "    vocab_size = len(embs_vocab)\n",
        "    embed_size = embed_size #TODO\n",
        "    hidden_size = hidden_size\n",
        "    num_conv_layers = num_conv_layers #UNUSED\n",
        "    num_categories = num_categories \n",
        "\n",
        "    self.embed = nn.Embedding.from_pretrained(embs_vocab)\n",
        "  \n",
        "    self.conv13 = nn.Conv2d(input_channels, hidden_size, (3, embed_size))\n",
        "    self.conv14 = nn.Conv2d(input_channels, hidden_size, (4, embed_size))\n",
        "    self.conv15 = nn.Conv2d(input_channels, hidden_size, (5, embed_size))\n",
        "\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "    self.fc = nn.Linear(num_conv_layers*hidden_size, num_categories)\n",
        "\n",
        "  def conv_and_pool(self, x, conv):\n",
        "    x = F.relu(conv(x)).squeeze(3)  # (batch_size, hidden_size, sent_length)\n",
        "    x = F.max_pool1d(x, x.size(2)).squeeze(2)\n",
        "    return x\n",
        "\n",
        "  def forward(self, x, x_length):\n",
        "    #TODO: PADDING ???? \n",
        "    x = self.embed(x)  # (batch_size, sent_length, embed_dim) ??\n",
        "    x = x.unsqueeze(1)  # (batch_size, input_channels, sent_length, embed_dim) ??\n",
        "    # print('after unsqueeze', x.size())\n",
        "\n",
        "    x1 = self.conv_and_pool(x,self.conv13) #(batch_size, hidden_size)\n",
        "    x2 = self.conv_and_pool(x,self.conv14) #(batch_size, hidden_size)\n",
        "    x3 = self.conv_and_pool(x,self.conv15) #(batch_size, hidden_size)\n",
        "    x = torch.cat((x1, x2, x3), 1) # (batch_size, 3*hidden_size)\n",
        "\n",
        "    x = self.dropout(x)  # (batch_size, 3*hidden_size)\n",
        "    logits = self.fc(x)  # (batch_size, num_categories)\n",
        "    return logits\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "31q3VLNku8fn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, iterator, optimizer, criterion):\n",
        "    epoch_loss = 0\n",
        "    iter_count = 0\n",
        "    print_every = 50\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for batch in iterator:\n",
        "        optimizer.zero_grad()   \n",
        "\n",
        "        text, text_lengths = batch.Tweet   \n",
        "        \n",
        "        if text.size(1) < 5:\n",
        "          continue \n",
        "\n",
        "        predictions = model(text, text_lengths)\n",
        "        \n",
        "        #CLTR VS ALL\n",
        "        loss = criterion(predictions, batch.Handle)   \n",
        "        # loss = criterion(predictions, batch.Party)             \n",
        "        loss.backward()       \n",
        "        optimizer.step()      \n",
        "        \n",
        "        epoch_loss += loss.item()  \n",
        "\n",
        "        if iter_count % print_every == 0:\n",
        "            print('%d %.4f' % (iter_count, loss))\n",
        "        iter_count+=1\n",
        "\n",
        "    return epoch_loss / len(iterator)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QBBed2k5P81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model, iterator, criterion):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    #no dropout layers\n",
        "    model.eval()\n",
        "    \n",
        "    #no autograd\n",
        "    with torch.no_grad():\n",
        "        for batch in iterator:\n",
        "            #retrieve text \n",
        "            text, text_lengths = batch.Tweet   \n",
        "            \n",
        "                    \n",
        "            if text.size(1) < 5:\n",
        "              continue \n",
        "\n",
        "            predictions = model(text, text_lengths)\n",
        "            \n",
        "             #CLTR VS ALL\n",
        "            #compute loss and accuracy\n",
        "            loss = criterion(predictions, batch.Handle)   \n",
        "            # loss = criterion(predictions, batch.Party)  \n",
        "            epoch_loss += loss.item()\n",
        "\n",
        "    return epoch_loss / len(iterator)        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkx3h5-S61lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_validate(model, train_iterator, valid_iterator, optimizer, criterion, n_epochs):\n",
        "  N_EPOCHS = n_epochs\n",
        "  best_valid_loss = float('inf')\n",
        "\n",
        "  for epoch in range(N_EPOCHS):\n",
        "      \n",
        "      train_loss = train(model, train_iterator, optimizer, criterion)\n",
        "      valid_loss = evaluate(model, valid_iterator, criterion)\n",
        "      \n",
        "      #save the best model\n",
        "      if valid_loss < best_valid_loss:\n",
        "          best_valid_loss = valid_loss\n",
        "          torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "      \n",
        "      print(f'\\t Train Loss: {train_loss:.3f}')\n",
        "      print(f'\\t Val. Loss: {valid_loss:.3f}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-Yx8nSNcEQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "import sklearn.metrics\n",
        "\n",
        "def test_scores(model, test_iterator):\n",
        "  # correct = 0\n",
        "  # total = 0\n",
        "  with torch.no_grad():\n",
        "    #there should be only one batch\n",
        "      for batch in test_iterator:\n",
        "        text, text_lengths = batch.Tweet\n",
        "        \n",
        "        #CLTR VS ALL\n",
        "        labels = batch.Handle\n",
        "        # labels = batch.Party\n",
        "\n",
        "        if text.size(1) < 5:\n",
        "          continue \n",
        "        predictions = model(text, text_lengths)\n",
        "        _, pred_classes = torch.max(predictions, 1)\n",
        "\n",
        "        print(text[pred_classes != labels][0])\n",
        "\n",
        "\n",
        "\n",
        "        # for val in range(200):\n",
        "                  \n",
        "        #   w2id = TEXT.vocab.stoi\n",
        "        #   id2w = dict([(value, key) for key, value in w2id.items()])\n",
        "        #   textttt = [id2w[i.item()] for i in text[pred_classes != labels][val]] \n",
        "        #   if textttt[0]!=\"\":\n",
        "        #     print(\" \".join(textttt))\n",
        "        #     print(labels[pred_classes != labels][val])\n",
        "        #     # print(labels[pred_classes != labels][val])\n",
        "\n",
        "\n",
        "        # total += labels.size(0)\n",
        "        # correct += (pred_classes == labels).sum().item()\n",
        "\n",
        "        print(\"ACCURACY\", sklearn.metrics.accuracy_score(labels.cpu().numpy(),  pred_classes.cpu().numpy()).round(3))\n",
        "        print(\"F1 SCORE\", sklearn.metrics.f1_score(labels.cpu().numpy(),  pred_classes.cpu().numpy(), average='micro').round(3))\n",
        "        print(\"PRECISION\", sklearn.metrics.precision_score(labels.cpu().numpy(),  pred_classes.cpu().numpy(), average='micro').round(3))\n",
        "        print(\"RECALL\", sklearn.metrics.recall_score(labels.cpu().numpy(),  pred_classes.cpu().numpy(), average='micro').round(3))\n",
        "\n",
        "        # return sklearn.metrics.f1_score(labels.cpu().numpy(),  pred_classes.cpu().numpy()).round(3)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GM49ra8tVX75",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CNN_EMBED_DIM = 100\n",
        "# CNN_HIDDEN_DIM = 100\n",
        "CNN_NUM_CONV_LAYERS = 3\n",
        "CNN_DROPOUT = 0.3\n",
        "CNN_LEARNING_RATE = 0.01\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "f1s = []\n",
        "\n",
        "for i in [5, 10, 20, 50, 100, 500]:\n",
        "  CNN_HIDDEN_DIM = i \n",
        "  cnn_model = CNN(embs_vocab, CNN_EMBED_DIM, CNN_HIDDEN_DIM, CNN_NUM_CONV_LAYERS, NUM_CATEGORIES, dropout=CNN_DROPOUT).to(device)\n",
        "  cnn_optimizer = optim.Adam(cnn_model.parameters(), lr = CNN_LEARNING_RATE)\n",
        "  cnn_criterion = nn.CrossEntropyLoss()\n",
        "  train_and_validate(cnn_model, train_iterator, valid_iterator, cnn_optimizer, cnn_criterion, NUM_EPOCHS)\n",
        "  f1 = test_scores(cnn_model, test_iterator)\n",
        "  f1s.append(f1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LbIEKi9YDRcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# test_scores(cnn_model, test_iterator)     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYHBIasg9DVg",
        "colab_type": "code",
        "outputId": "179f224c-6367-44b5-cd50-fc83f3dc3e64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(f1s)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.584, 0.791, 0.69, 0.817, 0.786, 0.675]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-vIQzs9J5eej",
        "colab_type": "text"
      },
      "source": [
        "#Bi-Directional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYC_qtQ48Ug2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BiDiLSTM(nn.Module):\n",
        "  def __init__(self, embs_vocab, embed_size, hidden_size, num_layers, num_categories, bidirectional=True, dropout=0.):\n",
        "    super(BiDiLSTM, self).__init__()\n",
        "\n",
        "    vocab_size = len(embs_vocab)\n",
        "    embed_size = embed_size #TODO\n",
        "    hidden_size = hidden_size\n",
        "    num_layers = num_layers\n",
        "    num_categories = num_categories \n",
        "    self.bidirectional = bidirectional\n",
        "\n",
        "    self.embed = nn.Embedding.from_pretrained(embs_vocab)\n",
        "  \n",
        "    #lstm layer\n",
        "    self.lstm = nn.LSTM(embed_size, \n",
        "                        hidden_size, \n",
        "                        num_layers=num_layers, \n",
        "                        bidirectional=self.bidirectional, \n",
        "                        dropout=dropout,\n",
        "                        batch_first=True)\n",
        "    \n",
        "    #dense layer\n",
        "    if self.bidirectional:\n",
        "      self.fc = nn.Linear(hidden_size * 2, num_categories)\n",
        "    else:\n",
        "      self.fc = nn.Linear(hidden_size, num_categories)\n",
        "\n",
        "\n",
        "  def forward(self, text, text_lengths):\n",
        "    embedded = self.embed(text) #[batch size, sent_len, emb dim]\n",
        "    packed = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, batch_first=True)\n",
        "    \n",
        "    output, (hidden, cell) = self.lstm(packed)\n",
        "\n",
        "    #hidden = [batch size, num layers * num directions,hid dim]\n",
        "    #cell = [batch size, num layers * num directions,hid dim]\n",
        "    \n",
        "    #concat the final forward and backward hidden state\n",
        "    if self.bidirectional:\n",
        "      hidden = torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)\n",
        "    else:\n",
        "      hidden = hidden.squeeze()   \n",
        "       \n",
        "    #hidden = [batch size, hid dim * num directions]\n",
        "    logits = self.fc(hidden)\n",
        "\n",
        "    return logits\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIulAb8m_pFG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LSTM_EMBED_DIM = 100\n",
        "# LSTM_HIDDEN_DIM = 82\n",
        "LSTM_NUM_LAYERS = 1\n",
        "LSTM_DROPOUT = 0.3\n",
        "LSTM_LEARNING_RATE = 0.001\n",
        "BIDIRECTIONAL = True\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "\n",
        "f1s = []\n",
        "\n",
        "for i in [20, 50]:\n",
        "  LSTM_HIDDEN_DIM = i\n",
        "  lstm_model = BiDiLSTM(embs_vocab, LSTM_EMBED_DIM, LSTM_HIDDEN_DIM, LSTM_NUM_LAYERS, NUM_CATEGORIES,bidirectional = BIDIRECTIONAL, dropout=LSTM_DROPOUT).to(device)\n",
        "  lstm_optimizer = optim.Adam(lstm_model.parameters(), lr = LSTM_LEARNING_RATE)\n",
        "  lstm_criterion = nn.CrossEntropyLoss()\n",
        "  train_and_validate(lstm_model, train_iterator, valid_iterator, lstm_optimizer, lstm_criterion, NUM_EPOCHS)\n",
        "  f1 = test_scores(lstm_model, test_iterator)\n",
        "  f1s.append(f1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYczHm0BGzLI",
        "colab_type": "code",
        "outputId": "aa1cce96-07c8-4c99-b535-561b360e661a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "f1s"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.63, 0.124, 0.312, 0.152, 0.047, 0.815]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pxsniCUhbWv",
        "colab_type": "code",
        "outputId": "6ca140c6-bac6-4fc6-946e-60de34f6fe80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "test_scores(lstm_model, test_iterator)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ACCURACY 0.841\n",
            "F1 SCORE 0.837\n",
            "PRECISION 0.791\n",
            "RECALL 0.889\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.837"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4gIV8_CiD01",
        "colab_type": "code",
        "outputId": "9199995b-e7d7-458b-9c13-30e4c4bccf66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#No. of trainable parameters\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    \n",
        "print(f'The LSTM model has {count_parameters(lstm_model):,} trainable parameters')\n",
        "print(f'The CNN model has {count_parameters(cnn_model):,} trainable parameters')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The LSTM model has 2,410,002 trainable parameters\n",
            "The CNN model has 604,502 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mb1rR7EQJxem",
        "colab_type": "code",
        "outputId": "f9bd17b6-fe9b-4277-d88e-c8f63ec33b78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "w2id = TEXT.vocab.stoi\n",
        "l2id = LABEL.vocab.stoi\n",
        "id2l = dict([(value, key) for key, value in l2id.items()])\n",
        "\n",
        "text = \"Make america great again.\"\n",
        "# \"We need to provide better healthcare\"\n",
        "# \"We need to tax less\"\n",
        "# \"We need to tax more\"\n",
        "\n",
        "\n",
        "import torchtext\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "tokenizer = get_tokenizer(\"spacy\")\n",
        "tokens = tokenizer(text)\n",
        "\n",
        "encoding = torch.tensor([[w2id[token] for token in tokens]]).to(device)\n",
        "length = torch.tensor([encoding.size(1)])\n",
        "\n",
        "predictions = lstm_model(encoding, length)\n",
        "_, pred_classes = torch.max(predictions, 1)\n",
        "\n",
        "\n",
        "\n",
        "cnn_predictions = cnn_model(encoding, length)\n",
        "_, cnn_pred_classes = torch.max(cnn_predictions, 1)\n",
        "\n",
        "print('CNN')\n",
        "print(F.softmax(cnn_predictions))\n",
        "print(text, \" LIKELY COMES FROM \", id2l[cnn_pred_classes.item()])\n",
        "\n",
        "print('LSTM')\n",
        "print(F.softmax(predictions))\n",
        "print(text, \" LIKELY COMES FROM \", id2l[pred_classes.item()])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN\n",
            "tensor([[0.6308, 0.3692]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "Make america great again.  LIKELY COMES FROM  realDonaldTrump\n",
            "LSTM\n",
            "tensor([[0.5658, 0.4342]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
            "Make america great again.  LIKELY COMES FROM  realDonaldTrump\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmAIxTP6mY07",
        "colab_type": "code",
        "outputId": "fa3b1841-ddcb-4875-aa79-62d2cb71b156",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "l2id = LABEL.vocab.stoi\n",
        "l2id"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<function torchtext.vocab._default_unk_index>,\n",
              "            {'Democrat': 1, 'Republican': 0})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Jt2TCGUUBGQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "w2id = TEXT.vocab.stoi\n",
        "w2id"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bi-Ma3p0TaaS",
        "colab_type": "code",
        "outputId": "75e186b0-1614-425f-a3f7-b073f7a304c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test_scores(lstm_model, test_iterator)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  14, 2565,    9,   41, 1432,   21,    4,   21,   67,   41, 1078, 1707,\n",
            "          41,  198,   21,    4,   21,   67,   21,   13,   21,  906,    5,   41,\n",
            "        3170,   11,  198,   21,    4,   21,   67,  733, 1717, 1037,  847,   16,\n",
            "        1271,    6,   10,    2,    2,    3], device='cuda:0')\n",
            "In 2017 # Nevadans in 10 counties , 7 in # NV02 , will have just 1 choice , it ’s unfair for them pay a penalty bc of Obama 's failed law ( 3/3 ) <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "I am sorry to hear about my friend & amp ; colleague @DorisMatsui ’s car accident .   I ’m glad to know she is doing well & amp ; wish her a speedy recovery <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Travel for def & amp ; mil personnel is not a https://t.co/ucKdra1SGZ , often it is mandatory & amp ; imperative to our security . I 'm glad we addressed # https://t.co/ucKdra1SGZ in # NDAA17 <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Like Orlando & amp ; Las Vegas , we mourn those we lost too soon & amp ; pledge support to the injured . But we can not accept these crimes as normal . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Call in now ! Join me for a Telephone # TownHall . Dial 1 - 877 - 229 - 8493 use https://t.co/ucKdra1SGZ # https://t.co/ucKdra1SGZ . Hear updates on my work in Cong … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "POTUS 's words demonstrate a moral compass where north is south , east is west . We must be of one course as a country - to condemn hate & amp ; racism . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "“ With Congress & amp ; @POTUS working hand - in - hand , we have made great strides . I ca n’t tell you how happy I am to see ou … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "If you clock - in & amp ; out , you deserve a # https://t.co/ucKdra1SGZ that allows you to survive & amp ; even get ahead . Coloradans voted to inc … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "In MN , # Medicaid covers : \n",
            "\n",
            " • 1 in 4 children \n",
            " • 1 in 2 nursing home residents \n",
            " • 1 in 2 people with disabilities \n",
            "\n",
            " The … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Mr. https://t.co/ucKdra1SGZ was my 7th grade math teacher & amp ; he changed my life . He looked out for me & amp ; got me on right track . On … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Glad my Storm tweet 's been taken by the storm & amp ; is keeping your eye on the storm ( # Matthew ) . Stay vigilant ! https://t.co/ucKdra1SGZ . https://t.co/ucKdra1SGZ … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "When I was with others on the battlefield & amp ; we saw a chance to save a life , we did n’t have a meeting about it ; we a … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "https://t.co/ucKdra1SGZ https://t.co/ucKdra1SGZ : Tomorrow at 6 pm , I 'm hosting a teletown hall to hear from you ! \n",
            " You can call directly to ( 888 ) 480 - 3626 … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Take a few minutes to read my op - ed via @dallasnews . The battle over the # CFPB is not about right & amp ; left , it is abo … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "It ’s # SmallBusinessWeek . \n",
            " 👉 https://t.co/ucKdra1SGZ % of small biz owners do n’t think new tax law puts them on level field w/ big biz \n",
            " 👉 https://t.co/ucKdra1SGZ … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "TODAY : \n",
            " 1 ) @YosemiteNPS has a FREE # EarthDay Festival , 10 am to 2 pm , at the Valley Visitor Center \n",
            " 2 ) https://t.co/ucKdra1SGZ is F … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "https://t.co/ucKdra1SGZ ️ The clock is ticking . https://t.co/ucKdra1SGZ ️ There are only 3 days left to sign up for health insurance . Do n't wait , act now by https://t.co/ucKdra1SGZ … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "My final vote as a member of the U.S. House of Representatives to bring clean water to the children of Flint , MI & amp ; keep govt open . # grateful <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "On # NationalWalkoutDay , I 'm carrying the photos & amp ; stories of Xavier Joy ( 23 ) , https://t.co/ucKdra1SGZ Holt ( 16 ) , https://t.co/ucKdra1SGZ Pendleton ( 15 … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Do n't get me wrong - a low unemployment rate & amp ; a lower https://t.co/ucKdra1SGZ rate is great . But when do Americans get a raise ? A https://t.co/ucKdra1SGZ … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "“ Habitat for Humanity is one of the best programs we have , and you all do a lot of good . ” Great to see you all in t … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "\" ’ I knew , and I still feel , it 's the best job in the world , ’ Tsongas said more than a decade after first taking off … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "As of Dec 15 , I 'll no longer tweet from this account . Please stay in touch by following me https://t.co/ucKdra1SGZ Thank you for the privilege . https://t.co/ucKdra1SGZ ️ 🇺 🇸 <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "For https://t.co/ucKdra1SGZ ago , # Medicare has protected health & amp ; well - being of American families , saving lives , & amp ; improving nation 's economic security . 1/ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "To all the cops on the beat , and to your loved ones : You do not fight alone . We are with you , and behind you , https://t.co/ucKdra1SGZ … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "https://t.co/ucKdra1SGZ on → “ High - speed rail is about convenience ; water is a basic human need . Where do I get my “ dams not trains ” s … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "🚨 🚨 🚨 Small Biz Confidence at All - Time High 🚨 🚨 🚨 \n",
            "\n",
            " Bloomberg on the @NFIB survey : \n",
            " \" ... producing one of the strongest read … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Great to meet https://t.co/ucKdra1SGZ & amp ; Angie https://t.co/ucKdra1SGZ & amp ; their kids https://t.co/ucKdra1SGZ , https://t.co/ucKdra1SGZ & amp ; https://t.co/ucKdra1SGZ today after their tour of @USCapitol . https://t.co/ucKdra1SGZ was … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Ruth https://t.co/ucKdra1SGZ But Ruth said , “ Do not urge me to leave you or turn back from following you ; for where you go , I will go , … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "# https://t.co/ucKdra1SGZ is a big deal in # NC10 . I 'm proud to support the industry and all the good - paying jobs it has created & amp ; … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "# https://t.co/ucKdra1SGZ is https://t.co/ucKdra1SGZ to @JBSA_Official , NSA TX , https://t.co/ucKdra1SGZ military & amp ; civilian https://t.co/ucKdra1SGZ , the DoD ’s only Level 1 https://t.co/ucKdra1SGZ Center & amp ; 2 … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "VOTE , VOTE , VOTE ! ! ! # TX22 Mayors , City Councils , School https://t.co/ucKdra1SGZ . Early voting began https://t.co/ucKdra1SGZ , ends https://t.co/ucKdra1SGZ .   5/5 final day . https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Is it too early for a # https://t.co/ucKdra1SGZ ?   Never .   Here is a picture of https://t.co/ucKdra1SGZ and me with a 4 District Constituent . I think h … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Erin , here ’s what I actually said : \n",
            " “ I think their goal was chaos . To say that we have seen or read evidence that ‘ w … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "If a Congressman is trying to https://t.co/ucKdra1SGZ you that America did n’t “ get had , ” give him the benefit of the doubt , maybe he “ got had . ” <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Meanwhile , state of good repair backlog of our nation 's # rail & amp ; # bus transit systems continues to grow $ 2.5 billion every single year . 2/ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "On this day in https://t.co/ucKdra1SGZ I came at the age of 8 from Puerto Rico to New York . On this day in https://t.co/ucKdra1SGZ I became a member of Congress . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Today is my https://t.co/ucKdra1SGZ ’s https://t.co/ucKdra1SGZ birthday ! https://t.co/ucKdra1SGZ , you ’re inspiration to me and my girls ! In her honor , I spoke on the House fl … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "https://t.co/ucKdra1SGZ great . Please call us at 202 - 225 - https://t.co/ucKdra1SGZ to schedule time to visit either in DC or https://t.co/ucKdra1SGZ . https://t.co/ucKdra1SGZ what is address of your church ? <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Check out this map of all the ' Farm to School ' gardens in OR ( there are more than 600 ! ) including quite a few in ou … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Praying for his wife Rose & amp ; all their loved ones . Blessed to have known James & amp ; forever grateful for his service . Rest in peace . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "The VA ( https://t.co/ucKdra1SGZ K employees & amp ; $ 180 billion annual budget ) has a sacred mission \" to care for him who has borne the battle … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "It 's # NationalParkWeek ! I 'm requesting   @USPS for a stamp to honor the https://t.co/ucKdra1SGZ citizens who were held at https://t.co/ucKdra1SGZ , now a Nat'l Park in HI . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "I join my fellow Americans in grieving the tragic loss of the men and women in Las Vegas . My thoughts go to their families & amp ; loved ones . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "My team & amp ; I work every day to be bridge for the Central Coast to the federal government & amp ; its resources . We break t … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Pay Raise ! Yes We Can ! That 's a great way to welcome a   New Year   ! Plus the @Eagles beat the https://t.co/ucKdra1SGZ ! 2017 https://t.co/ucKdra1SGZ … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "When sitting for hearings on # MuslimBan https://t.co/ucKdra1SGZ today , I hope # SCOTUS kept in mind the words & amp ; intent of the man who i m … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "@Sullied18 https://t.co/ucKdra1SGZ employment rate 2009 https://t.co/ucKdra1SGZ % \n",
            " https://t.co/ucKdra1SGZ employment rate dec 2017 https://t.co/ucKdra1SGZ % \n",
            " Today https://t.co/ucKdra1SGZ % .   So that 5 % drop https://t.co/ucKdra1SGZ to what exactly ? <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "\" Let 's face it , there is no Planet B \" - French President Emmanuel Macron to Congress today . \n",
            "\n",
            " He 's right , and the v … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Only way to stop executive gun control is to use the power of the purse .   Republicans took that off the table with the Omnibus . # tcot # 2A <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "It ’s back to Washington this week & amp ; I met up with members of the https://t.co/ucKdra1SGZ on my way to vote on the House Floor . Gr … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Sometimes people in Washington say something just ca n’t be done . But I say , where there ’s a will , there ’s a way .   Y … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Best of luck to the defending 2017 # https://t.co/ucKdra1SGZ champions as they start the Stanley Cup https://t.co/ucKdra1SGZ ! # https://t.co/ucKdra1SGZ ! Get that three - https://t.co/ucKdra1SGZ ! I # https://t.co/ucKdra1SGZ . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "At this same point in their https://t.co/ucKdra1SGZ ... \n",
            " https://t.co/ucKdra1SGZ Obama had 79 % of his nominees approved \n",
            " https://t.co/ucKdra1SGZ George W. Bush had 65 % \n",
            " https://t.co/ucKdra1SGZ Cl … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "She brings him good , not harm , all the days of her life ... \n",
            " Honor her for all that her hands have done , and let her … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Matthew https://t.co/ucKdra1SGZ and 6 \n",
            " \n",
            " \" And the angel answered and said https://t.co/ucKdra1SGZ the women , https://t.co/ucKdra1SGZ not ye : for I know that ye seek Jesus , w … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "https://t.co/ucKdra1SGZ version : \" We 've decided $ 1,000 is n't going to do much for you . So give it to us because we can use it bette … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            ".. neo - Nazis , and the https://t.co/ucKdra1SGZ are a scourge on society and have no place in our country . These are not values we hold as Oregonians . 2/2 <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "In 2017 , avg annual national premiums for Silver plan for a 40-year - old w/o a tax subsidy was $ https://t.co/ucKdra1SGZ . More than a $ 1,000 increase since 2014 <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "I had the honor of flying with Captain https://t.co/ucKdra1SGZ , and it ’s with a heavy heart we say Godspeed to Andy , & amp ; the other b … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "Happy to report that my bipartisan bill with Rep. Ted Lieu ( D - CA ) , \" https://t.co/ucKdra1SGZ the State Department , \" has passed out of c … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "I ’m so proud of the 7 young men who are now Eagle Scouts .    Thrilled to speak at the Eagle Scout Court of Honor on S … https://t.co/ucKdra1SGZ K <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(0, device='cuda:0')\n",
            "If you 're in # NE02 and planning a trip to DC , my staff can help you schedule a Capitol and White House tour . Visit : … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Stopped by Monroe Co Fair and got to meet https://t.co/ucKdra1SGZ ( the goat ) who was being shown by https://t.co/ucKdra1SGZ ! Had a great day at the f … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "A 4-year - old girl and a 2-year - old boy shot and killed in the https://t.co/ucKdra1SGZ area yesterday . We can not go on ( and los … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "@Amtrak 's trans - Hudson track connects not just NY & amp ; NJ , but the entire region . Because the Gateway Project is so i m … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "https://t.co/ucKdra1SGZ : https://t.co/ucKdra1SGZ and I just voted for Cap - Were votes https://t.co/ucKdra1SGZ & 435 in our https://t.co/ucKdra1SGZ . The rush was just starting as people got out of work <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Like all the men and women who wear the badge in # California , I took an oath to uphold the law . That means all of t … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Our men & amp ; women in uniform https://t.co/ucKdra1SGZ enormous sacrifices to keep us safe . In return , we promise a fair shot at a go … https://t.co/ucKdra1SGZ m <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "It 's been my greatest privilege to serve the people of HI . Your https://t.co/ucKdra1SGZ & amp ; compassion have helped shape my incredible journey these 20 + years . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Spent my last day in Congress after 46 yrs w/ DC staff who 've become my dear family . So long gang ! See you up in NY … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "We https://t.co/ucKdra1SGZ major push for FL & amp ; PR to get fed disaster relief education funding . PR just got $ 600 M but FL still need … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "The problem is n't welfare , it 's wages ! Millions of Americans work 2 or more jobs & amp ; still depend on SNAP to help fee … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "Great working w/ VA & amp ; schools at the Diversity & amp ; https://t.co/ucKdra1SGZ Summit to ensure proper care for all veterans through VA - Med School https://t.co/ucKdra1SGZ . <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "THREAD : When I saw this out - of - touch tweet , I thought about the people I 've met during my quest to # RaiseTheWage ... … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "I toured the https://t.co/ucKdra1SGZ VA this morning ; take a look at this video . They have a plan & amp ; things are moving forward . Al … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "# OTD in 1949 , # NATO was formed . The importance & amp ; impact of this partnership can not be overstated . In the interest o … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "CA , CT , IN , WA & amp ; OR have all adopted https://t.co/ucKdra1SGZ of the Gun Violence https://t.co/ucKdra1SGZ Order Act . They are saving lives wi … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "To # NY09 : As your Representative , I am working hard to fight against this budget & amp ; the effects of these tax cuts . I … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "We owe it to our states & amp ; local governments to ensure they are prepared with the knowledge & amp ; know - how to mitigate t … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "I hope to see you on May 14th at my town hall in Albany as I give an update on my work in Congress . https://t.co/ucKdra1SGZ the word … https://t.co/ucKdra1SGZ <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad> <pad>\n",
            "tensor(1, device='cuda:0')\n",
            "ACCURACY 0.676\n",
            "F1 SCORE 0.669\n",
            "PRECISION 0.665\n",
            "RECALL 0.672\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.669"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWb0m_Eh_p5l",
        "colab_type": "text"
      },
      "source": [
        "# Attention Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKV-rtbf1ewa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, dropout=0.):\n",
        "    \"\"\"\n",
        "    Inputs: \n",
        "      - `input_size`: an int representing the RNN input size.\n",
        "      - `hidden_size`: an int representing the RNN hidden size.\n",
        "    \"\"\"\n",
        "    super(Encoder, self).__init__()\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True,\n",
        "                      dropout=dropout, bidirectional=True)\n",
        "\n",
        "  def forward(self, inputs, lengths):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of source\n",
        "          sentences.\n",
        "      - `lengths`: a 1d-tensor of shape (batch_size,) representing the sequence\n",
        "          lengths of `inputs`.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: a 3d-tensor of shape\n",
        "        (batch_size, max_seq_length, hidden_size).\n",
        "      - `finals`: a 3d-tensor of shape (num_layers, batch_size, hidden_size).\n",
        "    \"\"\"\n",
        "    outputs, finals = self.rnn(inputs)\n",
        "    return outputs, finals\n",
        "\n",
        "class Attention(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size):\n",
        "    super(Attention, self).__init__()\n",
        "    self.attn = nn.Linear(hidden_size, hidden_size)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "  def forward(self, dec_out, enc_outs):\n",
        "    \"\"\"\n",
        "      - `dec_out`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n",
        "          the decoder hidden state.\n",
        "      - `enc_outs`: a 3d-tensor of shape\n",
        "          (batch_size, max_seq_length, hidden_size) representing the encoder\n",
        "          outputs for each decoding step to attend to. \n",
        "    \"\"\"\n",
        "    weighted_enc_hidden = self.attn(enc_outs) #dims: batch x seq_len X hidden\n",
        "    energies = torch.bmm(weighted_enc_hidden, dec_out.permute(1, 2, 0)) #dims: batch x seq_len x 1\n",
        "    alphas = self.softmax(energies)\n",
        "    return alphas #dims: batch x seq_len x 1\n",
        "    \n",
        "class AttentionDecoder(nn.Module):\n",
        "  \"\"\"An attention-based RNN decoder.\"\"\"\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, attention=None, dropout=0.):\n",
        "    \"\"\"\n",
        "      Inputs:\n",
        "        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n",
        "        - `attention`: this is your self-defined Attention object. You can\n",
        "            either define an individual class for your Attention and pass it\n",
        "            here or leave `attention` as None and just implement everything\n",
        "            here.\n",
        "    \"\"\"\n",
        "    super(AttentionDecoder, self).__init__()\n",
        "\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True,\n",
        "                      dropout=dropout, bidirectional=False)\n",
        "    \n",
        "    self.attn = attention\n",
        "\n",
        "    if attention is None:\n",
        "      self.attn = Attention(input_size, hidden_size)\n",
        "\n",
        "    self.w = nn.Linear(hidden_size * 2, hidden_size)\n",
        "    \n",
        "  def forward(self, inputs, encoder_hiddens, encoder_finals,  src_mask,\n",
        "              trg_mask, hidden=None, max_len=None):\n",
        "    \"\"\"Unroll the decoder one step at a time.\n",
        "    \n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of target\n",
        "          sentences (for teacher-forcing during training).\n",
        "      - `encoder_hiddens`: a 3d-tensor of shape\n",
        "          (batch_size, max_seq_length, hidden_size) representing the encoder\n",
        "          outputs for each decoding step to attend to. \n",
        "      - `encoder_finals`: a 3d-tensor of shape\n",
        "          (num_enc_layers, batch_size, hidden_size) representing the final\n",
        "          encoder hidden states used to initialize the initial decoder hidden\n",
        "          states.\n",
        "      - `src_mask`: a 3d-tensor of shape (batch_size, 1, max_seq_length)\n",
        "          representing the mask for source sentences.\n",
        "      - `trg_mask`: a 3d-tensor of shape (batch_size, 1, max_seq_length)\n",
        "          representing the mask for target sentences.\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n",
        "          the value to be used to initialize the initial decoder hidden states.\n",
        "          If None, then use `encoder_finals`.\n",
        "      - `max_len`: an int representing the maximum decoding length.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: (same as in Decoder) a 3d-tensor of shape\n",
        "          (batch_size, max_seq_length, hidden_size) representing the raw\n",
        "          decoder outputs (before converting to a `trg_vocab_size`-dim vector).\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size)\n",
        "          representing the last decoder hidden state.\n",
        "    \"\"\"\n",
        "\n",
        "    # The maximum number of steps to unroll the RNN.\n",
        "    if max_len is None:\n",
        "      # max_len = trg_mask.size(-1)\n",
        "        max_len = inputs.size(1)\n",
        "\n",
        "    if hidden is None:\n",
        "      hidden = self.init_hidden(encoder_finals)\n",
        "\n",
        "\n",
        "    outputs = []\n",
        "    all_alphas = []\n",
        "    \n",
        "    #todo: add connection of context to next hidden state\n",
        "    #todo maybe: use dec_out instead of hidden for attention \n",
        "\n",
        "    for i in range(max_len):\n",
        "      dec_out, hidden = self.rnn(inputs[:, i:i+1, :], hidden) # hidden dims: (1, batch_size, hidden_size)\n",
        "\n",
        "      alphas = self.attn(hidden, encoder_hiddens)  #dims: batch x seq_len x 1\n",
        "      all_alphas.append(alphas)\n",
        "      context = torch.bmm(encoder_hiddens.permute(0, 2, 1), alphas)  #dims: batch x hidden_size x 1\n",
        "      out = self.w(torch.cat((context.permute(2,0,1), hidden), dim=2)).squeeze(0) #dims: 1 x batch x hidden_size\n",
        "      outputs.append(out)\n",
        "\n",
        "    outputs = torch.stack(outputs, dim=1)  \n",
        "    return hidden, outputs, all_alphas\n",
        "\n",
        "  def init_hidden(self, encoder_finals):\n",
        "    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n",
        "    state.\"\"\"\n",
        "    decoder_init_hiddens = encoder_finals\n",
        "    ### Your code here!\n",
        "\n",
        "    return decoder_init_hiddens\n",
        "\n",
        "class EncoderAttentionDecoder(nn.Module):\n",
        "  \"\"\"A Encoder-Decoder architecture with attention.\n",
        "  \"\"\"\n",
        "  def __init__(self, encoder, decoder, src_embed , trg_embed, generator):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `encoder`: an `Encoder` object.\n",
        "      - `decoder`: an `AttentionDecoder` object.\n",
        "      - `src_embed`: an nn.Embedding object representing the lookup table for\n",
        "          input (source) sentences.\n",
        "      - `trg_embed`: an nn.Embedding object representing the lookup table for\n",
        "          output (target) sentences.\n",
        "      - `generator`: a `Generator` object. Essentially a linear mapping. See\n",
        "          the next code cell.\n",
        "    \"\"\"\n",
        "    super(EncoderAttentionDecoder, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.trg_embed = trg_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src_ids, trg_ids, src_lengths):\n",
        "    \"\"\"Take in and process masked source and tar get sequences.\n",
        "\n",
        "    Inputs:\n",
        "      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of source sentences of word ids.\n",
        "      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of target sentences of word ids.\n",
        "      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n",
        "        sequence length of `src_ids`.\n",
        "\n",
        "    Returns the decoder outputs, see the above cell.\n",
        "    \"\"\"\n",
        "    ### Your code here!\n",
        "    # You can refer to `EncoderDecoder` and extend from it.\n",
        "    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n",
        "    return self.decode(encoder_hiddens, encoder_finals, trg_ids[:, :-1])\n",
        "\n",
        "  def encode(self, src_ids, src_lengths):\n",
        "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
        "    \n",
        "  def decode(self, encoder_hiddens, encoder_finals, trg_ids, decoder_hidden=None):\n",
        "    return self.decoder(self.trg_embed(trg_ids), encoder_hiddens, encoder_finals, None, None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZztZfagEhT8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "LSTM_EMBED_DIM = 100\n",
        "LSTM_HIDDEN_DIM = 82\n",
        "LSTM_NUM_LAYERS = 1\n",
        "LSTM_DROPOUT = 0.3\n",
        "LSTM_LEARNING_RATE = 0.001\n",
        "BIDIRECTIONAL = True\n",
        "\n",
        "encoder = Encoder(LSTM_EMBED_DIM, LSTM_HIDDEN_DIM, LSTM_DROPOUT)\n",
        "decoder = AttentionDecoder(LSTM_EMBED_DIM, LSTM_HIDDEN_DIM, dropout = LSTM_DROPOUT)\n",
        "encdec  = EncoderAttentionDecoder(encoder, decoder, nn.Embedding.from_pretrained(embs_vocab), nn.Embedding.from_pretrained(embs_vocab) )\n",
        "\n",
        "# lstm_model = BiDiLSTM(embs_vocab, LSTM_EMBED_DIM, LSTM_HIDDEN_DIM, LSTM_NUM_LAYERS, NUM_CATEGORIES,bidirectional = BIDIRECTIONAL, dropout=LSTM_DROPOUT).to(device)\n",
        "# lstm_optimizer = optim.Adam(lstm_model.parameters(), lr = LSTM_LEARNING_RATE)\n",
        "# lstm_criterion = nn.CrossEntropyLoss()\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}